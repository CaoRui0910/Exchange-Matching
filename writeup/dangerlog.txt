Danger log：
1. Initially, we using session.commit() without cautious, so they’re bad transaction management.
2. We separate open sell order and open buy order into 2 tables. At first glance, we decided to use a global int and increase it by 1 every time there is a new sell order or buy order, and use thread.lock() to synchronize it. However, this is completely wrong. First, we use multiprocess instead of multithread so there are different global variables in different processes(they are independent). Second, if we try to lock it between multiple process, we serialize the processes and this makes our program have very low level of scalability. We solve this problem, by letting the database do synchronization for us. We create a ID sequence in Postgres and let the two tables share this sequence.
3. At first, we didn’t check the account id is legal or not to query or cancel the transaction. We noticed this and finally made our program check it.
4. We met bugs because we didn’t make a new Postgres connection per process under python multiprocessing environment, since the connection cannot be shared by different processes.
5. We initially store the time using int, this precision is far from enough. Since the transactions happen so fast in one second. We instead store more precise value, and output it in the response by converting it to int.
6. Initially, we made a very basic but hard-to-find error in the code on the query. For example, `select_query = select(SellOrder).where(sym == sym)`. In this statement, we don't realize that `sym == sym` is comparing an attribute named sym to itself, which leads us to get not all sell orders where sym is a particular value, but all sell orders where sym can be any value. Therefore, dealing with ambiguous attribute names is very important and in this case, we should qualify the attribute name with table name.
7. When implementing the testing infrastructure, in order to make it easier to build xml requests using test cases, we thought of storing request data in a list with elements as lists. This would allow us to include multiple requests with the same tag in a single xml request, for example multiple query requests.
